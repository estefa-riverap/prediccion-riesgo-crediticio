# -*- coding: utf-8 -*-
"""Despliegue Prestamos Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8p7-1JPc7Ym700WFPs8FlLw94qFd83T

# Despliegue

*   Cargamos el modelo
*   Cargamos los datos futuros
*   Preparar los datos futuros
*   Aplicamos el modelo para la predicción
*   Se descarga este arcvhivo .py
"""

#Importamos librerías básicas
#Ayudas
import pandas as pd # manipulacion dataframes
import numpy as np  # matrices y vectores
import matplotlib.pyplot as plt #gráfica

#Cargamos el modelo
import pickle
filename = 'modelo-class.pkl'
modelo, labelencoder,variables = pickle.load(open(filename, 'rb'))

# Cargamos los datos futuros
#data = pd.read_csv("Loan futuro.csv")
#data.head()

# Aquí va la interfaz gráfica
import streamlit as st

st.title('Predicción del riesgo de incumplimiento del pago de préstamos a persona natural')

age = st.slider('Edad', min_value=18, max_value=80, value=30, step=1)

income = st.number_input(
    'Ingreso anual (USD)',
    min_value=0
)

loan_amount = st.number_input(
    'Monto préstamo (USD)',
    min_value=500,
    max_value=1_000_000
)

credit_score = st.number_input(
    'Puntaje crediticio',
    min_value=300,
    max_value=850
)

months_employed = st.slider('Antiguedad laboral (meses)', min_value=0, max_value=250, value=12, step=1)

num_credit_lines = st.selectbox('Número de líneas de crédito', [1, 2, 3, 4])

interest_rate = st.slider('Tasa de interés', min_value=2, max_value=25, value=10, step=1)

employment_type = st.selectbox('Tipo de empleo', ['Self employed', 'Fulltime', 'Part time', 'Unemployed'])

has_mortgage = st.selectbox('Tiene hipoteca?', ['Yes', 'No'])

has_dependents= st.selectbox('Tiene dependientes? (Ej: hijos, padres, etc...)', ['Yes', 'No'])

has_cosigner = st.selectbox('Tiene codeudor?', ['Yes', 'No'])

datos = [[age,	income,	loan_amount,	credit_score,	months_employed,	num_credit_lines,	interest_rate,	employment_type,	has_mortgage,	has_dependents,	has_cosigner]]
data = pd.DataFrame(datos, columns=['Age',	'Income',	'LoanAmount',	'CreditScore', 'MonthsEmployed', 'NumCreditLines',	'InterestRate',	'EmploymentType',	'HasMortgage',	'HasDependents',	'HasCoSigner']) #Dataframe con los mismos nombres de variables

#Corrección tipos de datos
object_cols = data.select_dtypes(include='object').columns
for col in object_cols:
    data[col] = data[col].astype('category')

data.info()

#Se crean dummies a las variables predictoras categóricas (no a la variable obj)
data_preparada=data.copy()

data_preparada = pd.get_dummies(data_preparada, columns=['HasMortgage','HasDependents','HasCoSigner','EmploymentType'], drop_first=False, dtype=int) # Truee porque las categorias son binarias
data_preparada.head()

#Se adicionan las columnas faltantes, y se quitan las sobrantes, de modo que se ajuste a la variables de entrada del modlo
data_preparada=data_preparada.reindex(columns=variables,fill_value=0)
data_preparada.head()

# Normalización para los metodos Knn, RN y SVM
# Si se selecciono un árbol, no se normaliza...
#data_preparada[['age']]= min_max_scaler.transform(data_preparada[['age']])
#data_preparada.head()

#Hacemos la predicción con el modelo
Y_fut = modelo.predict(data_preparada)
print(Y_fut)

data['Predicción']=labelencoder.inverse_transform(Y_fut)
data.head()

"""# Predicciones

El modelo es un árbol de decisión y sus medidas de calidad son:

1. **AUC-ROC: 0,780**

La métrica AUC-ROC (Área bajo la curva ROC) mide la capacidad del modelo para distinguir correctamente entre las clases (en este caso, por ejemplo, clientes que incumplen vs. los que no incumplen).
Un valor de 0,780 indica un buen poder discriminatorio, es decir, el modelo logra diferenciar adecuadamente entre ambas categorías en la mayoría de los casos.

2. **Exactitud (Accuracy): 0,737**

La exactitud representa el porcentaje total de predicciones correctas realizadas por el modelo sobre el total de observaciones evaluadas.
Con un valor de 0,737, el modelo clasifica correctamente aproximadamente el 73,7% de los casos, mostrando un desempeño general sólido, aunque puede ser mejorado si existe un desbalance de clases.

3. **F1-score: 0,730**

El F1-score combina la precisión y el recall en una sola métrica armónica, lo que permite evaluar el equilibrio entre los falsos positivos y los falsos negativos.
Un valor de 0,730 sugiere que el modelo mantiene un buen balance entre precisión y cobertura, siendo consistente en sus predicciones positivas.

4. **Precisión (Precision): 0,730**

La precisión mide qué proporción de las predicciones positivas realmente pertenecen a la clase positiva.
Con un valor de 0,730, se interpreta que el 73% de las veces que el modelo predice un caso positivo, este es correcto, lo cual refleja un nivel de confiabilidad aceptable.

5. **Recall (Sensibilidad): 0,740**

El recall o sensibilidad indica la proporción de casos positivos correctamente identificados por el modelo respecto al total de casos positivos reales.
Un valor de 0,740 muestra que el modelo logra detectar el 74% de los casos positivos, lo cual evidencia buena capacidad de detección, especialmente útil en contextos donde los falsos negativos son costosos.

"""

data